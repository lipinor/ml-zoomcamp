{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "In this homework, we'll deploy the dino or dragon model we trained in the \n",
    "[previous homework](https://github.com/alexeygrigorev/mlbookcamp-code/blob/master/course-zoomcamp/cohorts/2022/08-deep-learning/homework.md).\n",
    "\n",
    "Download the model from here: \n",
    "\n",
    "https://github.com/SVizor42/ML_Zoomcamp/releases/download/dino-dragon-model/dino_dragon_10_0.899.h5\n",
    "\n",
    "\n",
    "## Question 1\n",
    "\n",
    "Now convert this model from Keras to TF-Lite format.\n",
    "\n",
    "What's the size of the **converted** model?\n",
    "\n",
    "- [ ] 21 Mb\n",
    "- [X] 43 Mb\n",
    "- [ ] 80 Mb\n",
    "- [ ] 164 Mb\n",
    "\n",
    "In order to answer this question, just run the convert.py file in this folder, which is a file with the below, and check for the size of the converted model that will be created.:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.load_model('dino_dragon_10_0.899.h5')\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with tf.io.gfile.GFile('dino-dragon-model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "```\n",
    "\n",
    "## Question 2\n",
    "\n",
    "To be able to use this model, we need to know the index of the input and the index of the output. \n",
    "\n",
    "What's the output index for this model?\n",
    "\n",
    "- [ ] 3\n",
    "- [ ] 7\n",
    "- [X] 13\n",
    "- [ ] 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_image_helper import create_preprocessor\n",
    "\n",
    "import tflite_runtime.interpreter as tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "preprocessor = create_preprocessor('xception', target_size=(299, 299))\n",
    "\n",
    "interpreter = tflite.Interpreter(model_path='dino-dragon-model.tflite')\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output index: 13\n"
     ]
    }
   ],
   "source": [
    "# Gets the input: the part of the network that takes in the array X\n",
    "input_details = interpreter.get_input_details()\n",
    "input_index = input_details[0]['index']\n",
    "\n",
    "# Gets the output: the part of the network with final predictions\n",
    "output_details = interpreter.get_output_details()\n",
    "output_index = output_details[0]['index']\n",
    "\n",
    "print(\"Output index: {}\".format(output_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the image\n",
    "\n",
    "You'll need some code for downloading and resizing images. You can use \n",
    "this code:\n",
    "\n",
    "```python\n",
    "from io import BytesIO\n",
    "from urllib import request\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img\n",
    "```\n",
    "\n",
    "For that, you'll need to have `pillow` installed:\n",
    "\n",
    "```bash\n",
    "pip install pillow\n",
    "```\n",
    "\n",
    "Let's download and resize this image: \n",
    "\n",
    "https://upload.wikimedia.org/wikipedia/commons/thumb/d/df/Smaug_par_David_Demaret.jpg/1280px-Smaug_par_David_Demaret.jpg\n",
    "\n",
    "Based on the previous homework, what should be the target size for the image?\n",
    "\n",
    "\n",
    "## Question 3\n",
    "\n",
    "Now we need to turn the image into numpy array and pre-process it. \n",
    "\n",
    "> Tip: Check the previous homework. What was the pre-processing \n",
    "> we did there?\n",
    "\n",
    "After the pre-processing, what's the value in the first pixel, the R channel?\n",
    "\n",
    "* 0.3353411\n",
    "* 0.5529412\n",
    "* 0.7458824\n",
    "* 0.9654902\n",
    "\n",
    "\n",
    "## Question 4\n",
    "\n",
    "Now let's apply this model to this image. What's the output of the model?\n",
    "\n",
    "* 0.17049132\n",
    "* 0.39009996\n",
    "* 0.60146114\n",
    "* 0.82448614"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00832aeeceb01ac6df2fc618c7a66526b081a1f3058727e4a1c1501650016635"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
