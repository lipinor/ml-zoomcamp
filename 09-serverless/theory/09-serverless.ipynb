{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serverless Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_image_helper import create_preprocessor\n",
    "\n",
    "import tflite_runtime.interpreter as tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = create_preprocessor('xception', target_size=(299, 299))\n",
    "\n",
    "image_url = 'http://bit.ly/mlbookcamp-pants'\n",
    "X = preprocessor.from_url(image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we load the model we previously created with tf-lite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tflite.Interpreter(model_path='clothing-model-v4.tflite')\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to use the model, we need to get its input (where X will go) and the output\n",
    "(where we get the predictions from):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the input: the part of the network that takes in the array X\n",
    "input_details = interpreter.get_input_details()\n",
    "input_index = input_details[0]['index']\n",
    "\n",
    "# Gets the output: the part of the network with final predictions\n",
    "output_details = interpreter.get_output_details()\n",
    "output_index = output_details[0]['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the model, take the X we previously prepared, put it into the input, invoke\n",
    "the interpreter, and get the results from the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': -1.8798647,\n",
       " 'hat': -4.7563086,\n",
       " 'longsleeve': -2.359531,\n",
       " 'outwear': -1.0892599,\n",
       " 'pants': 9.903781,\n",
       " 'shirt': -2.8261786,\n",
       " 'shoes': -3.648309,\n",
       " 'shorts': 3.241155,\n",
       " 'skirt': -2.6120946,\n",
       " 't-shirt': -4.8520336}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.set_tensor(input_index, X)\n",
    "interpreter.invoke()\n",
    "\n",
    "preds = interpreter.get_tensor(output_index) # This array contains the predictions\n",
    "\n",
    "# Labels for each class\n",
    "labels = [\n",
    "    'dress',\n",
    "    'hat',\n",
    "    'longsleeve',\n",
    "    'outwear',\n",
    "    'pants',\n",
    "    'shirt',\n",
    "    'shoes',\n",
    "    'shorts',\n",
    "    'skirt',\n",
    "    't-shirt'\n",
    "]\n",
    "\n",
    "# Final results\n",
    "results = dict(zip(labels, preds[0]))\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model correctly predicted the 'pants' class.\n",
    "\n",
    "### Code for the lambda function\n",
    "Now, we are going to put all this code together into a single script, `lambda_function.py`.\n",
    "\n",
    "Then, we create a Dockerfile and a Docker image. After building and running it, we can test it using the cell bellow, or the `test.py` script in this directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': -1.8798644542694092,\n",
       " 'hat': -4.7563090324401855,\n",
       " 'longsleeve': -2.359534740447998,\n",
       " 'outwear': -1.089264154434204,\n",
       " 'pants': 9.903782844543457,\n",
       " 'shirt': -2.8261802196502686,\n",
       " 'shoes': -3.648308753967285,\n",
       " 'shorts': 3.241154909133911,\n",
       " 'skirt': -2.6120963096618652,\n",
       " 't-shirt': -4.8520355224609375}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "data = {\n",
    "    \"url\": \"http://bit.ly/mlbookcamp-pants\"\n",
    "}\n",
    "\n",
    "url = \"http://localhost:8080/2015-03-31/functions/function/invocations\"\n",
    "results = requests.post(url, json=data).json()\n",
    "\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00832aeeceb01ac6df2fc618c7a66526b081a1f3058727e4a1c1501650016635"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
